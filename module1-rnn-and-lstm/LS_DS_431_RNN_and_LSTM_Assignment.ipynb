{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UknKmXBP0O8S",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "LhOn6KfX0O8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "D7H2dDev0O8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "EJl_mwh10O8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f97da762-8804-4c8a-c124-ffddb0d931d7"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czlQ72cekQR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3KnQxbvoNfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6486aa87-c38b-4d46-baa4-97317070c6f4"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1111146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbboV0r9oeW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAJ1QLtho3JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e50sL91pQgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67ac3127-a698-4b4a-ba63-09e8cfb7e030"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34723/34724 [============================>.] - ETA: 0s - loss: 1.9918\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"But with the word the time will bring on\"\n",
            "But with the word the time will bring one them fame chy not Mirice,— Goous comanty.  GHELLO. That goff soes you, where betce of them?     hathel; and truss; my appory offetrion not of sOe VOO. Dichan.  GORY. These Cid, not, from not this werily ast purtat'. Than meit of a nace, which you mmyen, And the Kanglewness her that our Truck the garth, So, ongeier thine at mice, to Themergers and garmatsh unter the Darfur he dimds and   good , a\n",
            "34724/34724 [==============================] - 156s 4ms/step - loss: 1.9918\n",
            "Epoch 2/10\n",
            "34722/34724 [============================>.] - ETA: 0s - loss: 1.6894\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \" men. I saw it, and told John a Gaunt he\"\n",
            " men. I saw it, and told John a Gaunt here, My cay, our hone to feer.                                        Enter V CENDARONEN, and as I as not a taster Code injuct.   Enter Flom he should to, me, in a shrilfolk lare!  NORS. Agay thou nathry, eartirn whet That thou sead, your ofter a stiliber not a tham all then this falt throre, Phrowcy have goor Joldy.     SI as resain he pose, but my wisse.  GOTIUS. Revery serve, Beasar, so, to we t\n",
            "34724/34724 [==============================] - 156s 4ms/step - loss: 1.6894\n",
            "Epoch 3/10\n",
            "34723/34724 [============================>.] - ETA: 0s - loss: 1.5959\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"that swoons;     Come all to help him, a\"\n",
            "that swoons;     Come all to help him, a rearn my lote thank-     And witw they actie by my have no strosh     come fare That thick! “Benclow, Caesar and: And must and comen of thanks with hath prove men     That both spoke beg man from thy mmand to wear,     For they do and my gives whence alfoce!   Enter   This for the Lord and or a wausing:  HAMLIFFEN. On! Curch this live     We propreto good; or when th true the Give you thou ask tr\n",
            "34724/34724 [==============================] - 155s 4ms/step - loss: 1.5958\n",
            "Epoch 4/10\n",
            "34723/34724 [============================>.] - ETA: 0s - loss: 1.5452\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"Where he should find you lions, finds yo\"\n",
            "Where he should find you lions, finds your Grace, will the Desard! Now to thouears, I sack money ment have te dount                                           Exit Lught, had I am, Jageand upon my wrands..         LINIO    CITIZEND. In that’s an ason. But is what pease, sir, I for gold, Addilgering the Lady to cabturish, for your sebull, Nay rasur.     She this who will vool at houre.   ENOBIS. [Aside] Sirn!' For follow unto notting.  PE\n",
            "34724/34724 [==============================] - 154s 4ms/step - loss: 1.5452\n",
            "Epoch 5/10\n",
            "34723/34724 [============================>.] - ETA: 0s - loss: 1.5116\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"an but stay you Where you’ll be loath to\"\n",
            "an but stay you Where you’ll be loath to the valophin ward.          Forlowes good does we prepary?     Old many thene lies day, sir, are dog, pelcezoned is. You shall we see;     And ginded of paster here, one to hast medlus’d me night, and such a both off are Agrints in the heed, my lords,       And op the windless put and more Indenates the devil tway this, all vall I know.   [_Exil._]  wonbory, art went mare To mine earlling adain c\n",
            "34724/34724 [==============================] - 155s 4ms/step - loss: 1.5116\n",
            "Epoch 6/10\n",
            "34716/34724 [============================>.] - ETA: 0s - loss: 1.4875\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"ort shall be.               [They conver\"\n",
            "ort shall be.               [They converdors murdent.  SYMANS. There is a revent.   TAILIA. That ouch'le that make reasure was or lign e’er To ill lest bid they shall st. Sweet's win’ratio-             Exeunt Yorks the KING EVDRIBUS, DUKE, and the MOTH. That after to it so, Upon he's for a sonstile your present of to all. Thy namivius, gentles!   QUEEN ELLENAT. Print is before throted and been could say,     In rough o’ the nameforth fa\n",
            "34724/34724 [==============================] - 156s 5ms/step - loss: 1.4875\n",
            "Epoch 7/10\n",
            "34716/34724 [============================>.] - ETA: 0s - loss: 1.4697\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \" I desire to find him so, that I may wor\"\n",
            " I desire to find him so, that I may worsw. You have we doth their hanted, with contents and offender may ago.   BULICELE. And everymall’s Mysepice; Their love bring that streemers to fulls   BRass. Heles coids are enclire by with too much Welse wit on the worth.  CLEOPATRE. My lord, with him lantly?   AUSONDRMEN. O mistric, you have gone that ARgive as. In heart writ       I about of Exewine          I have not comforting most lane hal\n",
            "34724/34724 [==============================] - 156s 4ms/step - loss: 1.4697\n",
            "Epoch 8/10\n",
            "34714/34724 [============================>.] - ETA: 0s - loss: 1.5049\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \" On the bat’s back I do fly After summer\"\n",
            " On the bat’s back I do fly After summerd take assasce What sheelingers, wouse though, Gentle deceive has you havith your nasten with horrakes to bebul's sell-go may The harchick wor by The Ofe, Wel't are? The he at ususe as he’s which their morninated;       Onetious-fair eat yegs,    So gentle to them hat the patience monum, Are is doth by chmotity say he noture that his breath.  CLOWN. Made, pies Host (ut to the eat you sheet, I cuts\n",
            "34724/34724 [==============================] - 158s 5ms/step - loss: 1.5049\n",
            "Epoch 9/10\n",
            "34717/34724 [============================>.] - ETA: 0s - loss: 1.4595\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ssing shame     That I, unworthy body as\"\n",
            "ssing shame     That I, unworthy body as objectish. Nore a day, done? Is thou both'st thee weep,     S'Ach moment into them back'd, -eaver     Theye with have high hand loverd! To we cousen hope in this Penratch’d soney, yet God’s best here find are; a offence citure hence. She can then are the weeks’st rent.—Craised my woman; But hagshew, potse.   DUKE. Though? I’ll dear an med.          MAd SARD. And if the subels winks the way. Yet d\n",
            "34724/34724 [==============================] - 156s 4ms/step - loss: 1.4595\n",
            "Epoch 10/10\n",
            "34714/34724 [============================>.] - ETA: 0s - loss: 1.4405\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"ere     Ere sun-rise, prayers from prese\"\n",
            "ere     Ere sun-rise, prayers from presents To you That I cannot wept your death, Love, keep I’ll     provoke strong that concord with the blenty dear ontonicians.  BELARIUS. No, could not hear milly death to comes.   DUMAIN. An compet done, me’t to; but your patring the bush in rages]     Some false God far’d of him. Forth servalt and tears friends: give you too; and you shall be but charms Leights his sleaths and tures with Scut.     \n",
            "34724/34724 [==============================] - 157s 5ms/step - loss: 1.4406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6e975d080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmIlflROyQmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shakespeare(length=100):    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    output = sentence\n",
        "    for i in range(length):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        output += next_char\n",
        "    return output"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyXmM5cA6m5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c086adb8-d7a4-490f-dd17-02565a9b6b72"
      },
      "source": [
        "shakespeare(1000)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" we are here.   KATHARINE. It is not you in Enolacher’s home. To compabuting sland me of Chail, and graval in such form feed: Your peaw of youd legged from speak, from thy hands and munthish upon to sluine, They call nonering time I sadien my nausight.   KING JOHN. That well earth upon thy son, being nover that befess.   LUCIUS. Nay, if Buritice; sing my man so?  PATRIAD. No. if th’ are meane is.  GHOET. That hear upon the shrows. The more the Landers! That come too why if it feiting builditaz and present; Than their sacredismen that my noble rame.   KING, and see oneret. Some and Rome.   SIBYNA. The scannent, my lord, and first quothes     The law Is this tongue to brief.  KING. The Posting house. And it is the Duke bid.     Heaven had took her cormpitrian.  OLIVIA. Now. At since he cay, weep the chouthing excurs,     And there, in gurrus and horsemation     Untale with mealame and a cabterch’d;?   PRIACE. I propinator to yet, I thy a tooching of thy mistrain; The brange milas.  ORLENIO. Of usible.  A Musim, you'nd doging G\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}